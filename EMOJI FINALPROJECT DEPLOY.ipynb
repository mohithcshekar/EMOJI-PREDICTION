{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#IMPORTING THE LIBRARIES\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "400000  words loaded!\n"
     ]
    }
   ],
   "source": [
    "train=pd.read_csv('Finalemoji.csv')\n",
    "emoji_dictionary = {\"0\": \"\\u2764\\uFE0F\",    # :heart: prints a black instead of red heart depending on the font\n",
    "                    \"1\": \":baseball:\",\n",
    "                    \"2\": \":beaming_face_with_smiling_eyes:\",\n",
    "                    \"3\": \":downcast_face_with_sweat:\",\n",
    "                    \"4\": \":fork_and_knife:\",\n",
    "                    \"6\":\":fire:\",\n",
    "                    \"7\":\":face_blowing_a_kiss:\",\n",
    "                    \"8\":\":chestnut:\",\n",
    "                    \"9\":\":flexed_biceps:\"\n",
    "                   }\n",
    "X_train=train['0']\n",
    "Y_train=train['1']\n",
    "Y_train1=to_categorical(Y_train,num_classes=5)\n",
    "def loadGloveModel(File):\n",
    "    print(\"Loading Glove Model\")\n",
    "    f = open(File,'r',encoding='utf-8')\n",
    "    gloveModel = {}\n",
    "    for line in f:\n",
    "        #print(line)\n",
    "        splitLines = line.split()\n",
    "        #print(splitlines)\n",
    "        word = splitLines[0]\n",
    "        wordEmbedding = np.array([float(value) for value in splitLines[1:]])\n",
    "        gloveModel[word] = wordEmbedding\n",
    "    print(len(gloveModel),\" words loaded!\")\n",
    "    return gloveModel\n",
    "#FUNCTION IS CALLED\n",
    "power=loadGloveModel('glove.6B.50d.txt')\n",
    "def embedding(X):\n",
    "    max_len=10\n",
    "    embdim=50\n",
    "    #YOU HAVE TO CREATE AN EMBEDDING LAYER\n",
    "    embeddinglayer=np.zeros((X.shape[0],max_len,embdim))\n",
    "    #YOU HAVE CREATED AN EMBEDDING LAYER\n",
    "    for i in range(X.shape[0]):\n",
    "        alllines=X[i].split()\n",
    "        \n",
    "        for idx in range(len(alllines)):\n",
    "            try:\n",
    "                embeddinglayer[i][idx]=power[alllines[idx].lower()]\n",
    "            except:\n",
    "                embeddinglayer[i][idx]=np.zeros((50,))\n",
    "    return embeddinglayer\n",
    "#FUNCTION IS CALLED\n",
    "embedding_train_matrix=embedding(X_train)\n",
    "#MODEL CREATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 10, 64)            29440     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 62,789\n",
      "Trainable params: 62,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#CREATING THE MODEL\n",
    "model =Sequential()\n",
    "model.add(LSTM(64,input_shape=(10,50),return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(LSTM(64,input_shape=(10,50)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150 samples, validate on 38 samples\n",
      "Epoch 1/150\n",
      "150/150 [==============================] - 3s 20ms/step - loss: 1.5936 - acc: 0.3067 - val_loss: 1.5751 - val_acc: 0.2632\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.26316, saving model to best_modelf4.h5\n",
      "Epoch 2/150\n",
      "150/150 [==============================] - 0s 873us/step - loss: 1.5474 - acc: 0.3400 - val_loss: 1.5451 - val_acc: 0.2632\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.26316\n",
      "Epoch 3/150\n",
      "150/150 [==============================] - 0s 888us/step - loss: 1.5269 - acc: 0.3533 - val_loss: 1.5216 - val_acc: 0.2895\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.26316 to 0.28947, saving model to best_modelf4.h5\n",
      "Epoch 4/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 1.5043 - acc: 0.3733 - val_loss: 1.4992 - val_acc: 0.3158\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.28947 to 0.31579, saving model to best_modelf4.h5\n",
      "Epoch 5/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 1.4810 - acc: 0.3933 - val_loss: 1.4791 - val_acc: 0.3684\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.31579 to 0.36842, saving model to best_modelf4.h5\n",
      "Epoch 6/150\n",
      "150/150 [==============================] - 0s 944us/step - loss: 1.4402 - acc: 0.4000 - val_loss: 1.4602 - val_acc: 0.3947\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.36842 to 0.39474, saving model to best_modelf4.h5\n",
      "Epoch 7/150\n",
      "150/150 [==============================] - 0s 916us/step - loss: 1.3957 - acc: 0.4467 - val_loss: 1.4442 - val_acc: 0.2632\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.39474\n",
      "Epoch 8/150\n",
      "150/150 [==============================] - 0s 982us/step - loss: 1.3514 - acc: 0.4867 - val_loss: 1.4238 - val_acc: 0.3421\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.39474\n",
      "Epoch 9/150\n",
      "150/150 [==============================] - 0s 890us/step - loss: 1.2916 - acc: 0.5333 - val_loss: 1.3885 - val_acc: 0.3947\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.39474\n",
      "Epoch 10/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 1.1939 - acc: 0.5600 - val_loss: 1.3359 - val_acc: 0.3947\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.39474\n",
      "Epoch 11/150\n",
      "150/150 [==============================] - 0s 956us/step - loss: 1.1327 - acc: 0.6067 - val_loss: 1.2861 - val_acc: 0.3947\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.39474\n",
      "Epoch 12/150\n",
      "150/150 [==============================] - 0s 913us/step - loss: 1.0167 - acc: 0.6467 - val_loss: 1.2768 - val_acc: 0.4474\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.39474 to 0.44737, saving model to best_modelf4.h5\n",
      "Epoch 13/150\n",
      "150/150 [==============================] - 0s 890us/step - loss: 0.9401 - acc: 0.6933 - val_loss: 1.2431 - val_acc: 0.4737\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.44737 to 0.47368, saving model to best_modelf4.h5\n",
      "Epoch 14/150\n",
      "150/150 [==============================] - 0s 960us/step - loss: 0.8711 - acc: 0.7067 - val_loss: 1.1771 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.47368 to 0.55263, saving model to best_modelf4.h5\n",
      "Epoch 15/150\n",
      "150/150 [==============================] - 0s 927us/step - loss: 0.7541 - acc: 0.7200 - val_loss: 1.1987 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.55263\n",
      "Epoch 16/150\n",
      "150/150 [==============================] - 0s 931us/step - loss: 0.7700 - acc: 0.7267 - val_loss: 1.1974 - val_acc: 0.4474\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.55263\n",
      "Epoch 17/150\n",
      "150/150 [==============================] - 0s 976us/step - loss: 0.7204 - acc: 0.7267 - val_loss: 1.1469 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.55263 to 0.57895, saving model to best_modelf4.h5\n",
      "Epoch 18/150\n",
      "150/150 [==============================] - 0s 951us/step - loss: 0.6715 - acc: 0.7467 - val_loss: 1.2224 - val_acc: 0.5263\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.57895\n",
      "Epoch 19/150\n",
      "150/150 [==============================] - 0s 951us/step - loss: 0.6158 - acc: 0.7733 - val_loss: 1.1071 - val_acc: 0.5263\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.57895\n",
      "Epoch 20/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.5506 - acc: 0.7800 - val_loss: 1.1022 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.57895\n",
      "Epoch 21/150\n",
      "150/150 [==============================] - 0s 935us/step - loss: 0.4668 - acc: 0.8333 - val_loss: 1.1633 - val_acc: 0.5263\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.57895\n",
      "Epoch 22/150\n",
      "150/150 [==============================] - 0s 930us/step - loss: 0.5061 - acc: 0.8000 - val_loss: 1.1068 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.57895\n",
      "Epoch 23/150\n",
      "150/150 [==============================] - 0s 952us/step - loss: 0.4147 - acc: 0.8867 - val_loss: 1.1530 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.57895\n",
      "Epoch 24/150\n",
      "150/150 [==============================] - 0s 944us/step - loss: 0.4071 - acc: 0.8733 - val_loss: 1.0712 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.57895\n",
      "Epoch 25/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.4358 - acc: 0.8400 - val_loss: 0.9298 - val_acc: 0.6316\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.57895 to 0.63158, saving model to best_modelf4.h5\n",
      "Epoch 26/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3610 - acc: 0.8800 - val_loss: 1.0118 - val_acc: 0.6316\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.63158\n",
      "Epoch 27/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3418 - acc: 0.8933 - val_loss: 1.1822 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.63158\n",
      "Epoch 28/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3269 - acc: 0.8733 - val_loss: 0.9463 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.63158\n",
      "Epoch 29/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2735 - acc: 0.9067 - val_loss: 0.9340 - val_acc: 0.6316\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.63158\n",
      "Epoch 30/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.3333 - acc: 0.8467 - val_loss: 1.1582 - val_acc: 0.6316\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.63158\n",
      "Epoch 31/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2650 - acc: 0.9133 - val_loss: 1.0328 - val_acc: 0.6579\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.63158 to 0.65789, saving model to best_modelf4.h5\n",
      "Epoch 32/150\n",
      "150/150 [==============================] - 0s 907us/step - loss: 0.2678 - acc: 0.9067 - val_loss: 1.0968 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.65789\n",
      "Epoch 33/150\n",
      "150/150 [==============================] - 0s 907us/step - loss: 0.2298 - acc: 0.9400 - val_loss: 1.1353 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.65789\n",
      "Epoch 34/150\n",
      "150/150 [==============================] - 0s 854us/step - loss: 0.2242 - acc: 0.9333 - val_loss: 1.1098 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.65789\n",
      "Epoch 35/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.2039 - acc: 0.9400 - val_loss: 1.0460 - val_acc: 0.6579\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.65789\n",
      "Epoch 36/150\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2173 - acc: 0.9333 - val_loss: 1.1129 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.65789\n",
      "Epoch 37/150\n",
      "150/150 [==============================] - 0s 924us/step - loss: 0.1541 - acc: 0.9533 - val_loss: 1.1720 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.65789\n",
      "Epoch 38/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1539 - acc: 0.9667 - val_loss: 1.0917 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.65789\n",
      "Epoch 39/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1802 - acc: 0.9400 - val_loss: 1.2362 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.65789\n",
      "Epoch 40/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1445 - acc: 0.9600 - val_loss: 1.2661 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.65789\n",
      "Epoch 41/150\n",
      "150/150 [==============================] - 0s 932us/step - loss: 0.1433 - acc: 0.9600 - val_loss: 1.2288 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.65789\n",
      "Epoch 42/150\n",
      "150/150 [==============================] - 0s 890us/step - loss: 0.1107 - acc: 0.9800 - val_loss: 1.3647 - val_acc: 0.5526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00042: val_acc did not improve from 0.65789\n",
      "Epoch 43/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1236 - acc: 0.9733 - val_loss: 1.2100 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.65789\n",
      "Epoch 44/150\n",
      "150/150 [==============================] - 0s 941us/step - loss: 0.0895 - acc: 0.9667 - val_loss: 1.1864 - val_acc: 0.6579\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.65789\n",
      "Epoch 45/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0723 - acc: 0.9800 - val_loss: 1.2218 - val_acc: 0.6316\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.65789\n",
      "Epoch 46/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1323 - acc: 0.9600 - val_loss: 1.3409 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.65789\n",
      "Epoch 47/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0701 - acc: 0.9867 - val_loss: 1.3254 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.65789\n",
      "Epoch 48/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0550 - acc: 0.9867 - val_loss: 1.3277 - val_acc: 0.6579\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.65789\n",
      "Epoch 49/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1076 - acc: 0.9533 - val_loss: 1.3829 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.65789\n",
      "Epoch 50/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1159 - acc: 0.9533 - val_loss: 1.5806 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.65789\n",
      "Epoch 51/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.1099 - acc: 0.9600 - val_loss: 1.5057 - val_acc: 0.5263\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.65789\n",
      "Epoch 52/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0712 - acc: 0.9933 - val_loss: 1.3938 - val_acc: 0.6579\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.65789\n",
      "Epoch 53/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0638 - acc: 0.9867 - val_loss: 1.3921 - val_acc: 0.6316\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.65789\n",
      "Epoch 54/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0655 - acc: 0.9800 - val_loss: 1.4663 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.65789\n",
      "Epoch 55/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0393 - acc: 0.9867 - val_loss: 1.5538 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.65789\n",
      "Epoch 56/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0515 - acc: 0.9933 - val_loss: 1.5791 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.65789\n",
      "Epoch 57/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0458 - acc: 0.9933 - val_loss: 1.4946 - val_acc: 0.6316\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.65789\n",
      "Epoch 58/150\n",
      "150/150 [==============================] - 0s 919us/step - loss: 0.0558 - acc: 0.9800 - val_loss: 1.4387 - val_acc: 0.6579\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.65789\n",
      "Epoch 59/150\n",
      "150/150 [==============================] - 0s 818us/step - loss: 0.0528 - acc: 0.9800 - val_loss: 1.7457 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.65789\n",
      "Epoch 60/150\n",
      "150/150 [==============================] - 0s 788us/step - loss: 0.0507 - acc: 0.9933 - val_loss: 1.8364 - val_acc: 0.5263\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.65789\n",
      "Epoch 61/150\n",
      "150/150 [==============================] - 0s 723us/step - loss: 0.0510 - acc: 0.9867 - val_loss: 1.4418 - val_acc: 0.6842\n",
      "\n",
      "Epoch 00061: val_acc improved from 0.65789 to 0.68421, saving model to best_modelf4.h5\n",
      "Epoch 62/150\n",
      "150/150 [==============================] - 0s 788us/step - loss: 0.0813 - acc: 0.9733 - val_loss: 1.7319 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.68421\n",
      "Epoch 63/150\n",
      "150/150 [==============================] - 0s 960us/step - loss: 0.1359 - acc: 0.9667 - val_loss: 2.1207 - val_acc: 0.5263\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.68421\n",
      "Epoch 64/150\n",
      "150/150 [==============================] - 0s 907us/step - loss: 0.0976 - acc: 0.9667 - val_loss: 1.6601 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.68421\n",
      "Epoch 65/150\n",
      "150/150 [==============================] - 0s 782us/step - loss: 0.1594 - acc: 0.9400 - val_loss: 1.7994 - val_acc: 0.5263\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.68421\n",
      "Epoch 66/150\n",
      "150/150 [==============================] - 0s 760us/step - loss: 0.1300 - acc: 0.9667 - val_loss: 1.8595 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.68421\n",
      "Epoch 67/150\n",
      "150/150 [==============================] - 0s 709us/step - loss: 0.0396 - acc: 0.9867 - val_loss: 1.5851 - val_acc: 0.6579\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.68421\n",
      "Epoch 68/150\n",
      "150/150 [==============================] - 0s 691us/step - loss: 0.0951 - acc: 0.9733 - val_loss: 1.6500 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.68421\n",
      "Epoch 69/150\n",
      "150/150 [==============================] - 0s 745us/step - loss: 0.0405 - acc: 1.0000 - val_loss: 1.8306 - val_acc: 0.5263\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.68421\n",
      "Epoch 70/150\n",
      "150/150 [==============================] - 0s 718us/step - loss: 0.0463 - acc: 0.9933 - val_loss: 1.8785 - val_acc: 0.5263\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.68421\n",
      "Epoch 71/150\n",
      "150/150 [==============================] - 0s 733us/step - loss: 0.0514 - acc: 0.9933 - val_loss: 1.7157 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.68421\n",
      "Epoch 72/150\n",
      "150/150 [==============================] - 0s 937us/step - loss: 0.0489 - acc: 0.9933 - val_loss: 1.6932 - val_acc: 0.6316\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.68421\n",
      "Epoch 73/150\n",
      "150/150 [==============================] - 0s 773us/step - loss: 0.0218 - acc: 1.0000 - val_loss: 1.6930 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.68421\n",
      "Epoch 74/150\n",
      "150/150 [==============================] - 0s 752us/step - loss: 0.0214 - acc: 1.0000 - val_loss: 1.6758 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.68421\n",
      "Epoch 75/150\n",
      "150/150 [==============================] - 0s 735us/step - loss: 0.0418 - acc: 0.9867 - val_loss: 1.7323 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.68421\n",
      "Epoch 76/150\n",
      "150/150 [==============================] - 0s 694us/step - loss: 0.0199 - acc: 1.0000 - val_loss: 1.7699 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.68421\n",
      "Epoch 77/150\n",
      "150/150 [==============================] - 0s 905us/step - loss: 0.0290 - acc: 0.9933 - val_loss: 1.7879 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.68421\n",
      "Epoch 78/150\n",
      "150/150 [==============================] - 0s 890us/step - loss: 0.0525 - acc: 0.9867 - val_loss: 1.6922 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.68421\n",
      "Epoch 79/150\n",
      "150/150 [==============================] - 0s 849us/step - loss: 0.0415 - acc: 0.9867 - val_loss: 1.7266 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.68421\n",
      "Epoch 80/150\n",
      "150/150 [==============================] - 0s 910us/step - loss: 0.0177 - acc: 1.0000 - val_loss: 1.7527 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.68421\n",
      "Epoch 81/150\n",
      "150/150 [==============================] - 0s 879us/step - loss: 0.0161 - acc: 1.0000 - val_loss: 1.7488 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.68421\n",
      "Epoch 82/150\n",
      "150/150 [==============================] - 0s 971us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 1.7736 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.68421\n",
      "Epoch 83/150\n",
      "150/150 [==============================] - 0s 947us/step - loss: 0.0164 - acc: 1.0000 - val_loss: 1.8126 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.68421\n",
      "Epoch 84/150\n",
      "150/150 [==============================] - 0s 925us/step - loss: 0.0239 - acc: 0.9867 - val_loss: 1.8461 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.68421\n",
      "Epoch 85/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0104 - acc: 1.0000 - val_loss: 1.8656 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.68421\n",
      "Epoch 86/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0144 - acc: 1.0000 - val_loss: 1.8768 - val_acc: 0.5789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00086: val_acc did not improve from 0.68421\n",
      "Epoch 87/150\n",
      "150/150 [==============================] - 0s 952us/step - loss: 0.0162 - acc: 0.9933 - val_loss: 1.8999 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.68421\n",
      "Epoch 88/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0108 - acc: 1.0000 - val_loss: 1.9182 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.68421\n",
      "Epoch 89/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0163 - acc: 1.0000 - val_loss: 1.9401 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.68421\n",
      "Epoch 90/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 1.9508 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.68421\n",
      "Epoch 91/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0299 - acc: 0.9933 - val_loss: 2.0592 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.68421\n",
      "Epoch 92/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0093 - acc: 1.0000 - val_loss: 2.0566 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.68421\n",
      "Epoch 93/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0092 - acc: 1.0000 - val_loss: 2.0276 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.68421\n",
      "Epoch 94/150\n",
      "150/150 [==============================] - 0s 932us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 2.0427 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.68421\n",
      "Epoch 95/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 2.0620 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.68421\n",
      "Epoch 96/150\n",
      "150/150 [==============================] - 0s 922us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 2.0802 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.68421\n",
      "Epoch 97/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 2.0944 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.68421\n",
      "Epoch 98/150\n",
      "150/150 [==============================] - 0s 856us/step - loss: 0.0099 - acc: 1.0000 - val_loss: 2.1034 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.68421\n",
      "Epoch 99/150\n",
      "150/150 [==============================] - 0s 979us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 2.1095 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.68421\n",
      "Epoch 100/150\n",
      "150/150 [==============================] - 0s 908us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 2.1307 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.68421\n",
      "Epoch 101/150\n",
      "150/150 [==============================] - 0s 882us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 2.1738 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.68421\n",
      "Epoch 102/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 2.2314 - val_acc: 0.5263\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.68421\n",
      "Epoch 103/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0079 - acc: 1.0000 - val_loss: 2.2394 - val_acc: 0.5263\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.68421\n",
      "Epoch 104/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 2.2231 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.68421\n",
      "Epoch 105/150\n",
      "150/150 [==============================] - 0s 828us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 2.1845 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.68421\n",
      "Epoch 106/150\n",
      "150/150 [==============================] - 0s 912us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.1427 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.68421\n",
      "Epoch 107/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 2.1160 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.68421\n",
      "Epoch 108/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.1027 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.68421\n",
      "Epoch 109/150\n",
      "150/150 [==============================] - 0s 885us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 2.1387 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.68421\n",
      "Epoch 110/150\n",
      "150/150 [==============================] - 0s 977us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.1824 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.68421\n",
      "Epoch 111/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 2.2202 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.68421\n",
      "Epoch 112/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.2505 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.68421\n",
      "Epoch 113/150\n",
      "150/150 [==============================] - 0s 855us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 2.2701 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.68421\n",
      "Epoch 114/150\n",
      "150/150 [==============================] - 0s 903us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.2769 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.68421\n",
      "Epoch 115/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 2.2585 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.68421\n",
      "Epoch 116/150\n",
      "150/150 [==============================] - 0s 952us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.2542 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.68421\n",
      "Epoch 117/150\n",
      "150/150 [==============================] - 0s 974us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 2.2590 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.68421\n",
      "Epoch 118/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0093 - acc: 0.9933 - val_loss: 2.2386 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.68421\n",
      "Epoch 119/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 2.1950 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.68421\n",
      "Epoch 120/150\n",
      "150/150 [==============================] - 0s 964us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 2.2139 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.68421\n",
      "Epoch 121/150\n",
      "150/150 [==============================] - 0s 891us/step - loss: 0.0301 - acc: 0.9867 - val_loss: 2.1908 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.68421\n",
      "Epoch 122/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0285 - acc: 0.9933 - val_loss: 2.1850 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.68421\n",
      "Epoch 123/150\n",
      "150/150 [==============================] - 0s 998us/step - loss: 0.0132 - acc: 1.0000 - val_loss: 2.1747 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.68421\n",
      "Epoch 124/150\n",
      "150/150 [==============================] - 0s 871us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 2.1489 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.68421\n",
      "Epoch 125/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 2.1507 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.68421\n",
      "Epoch 126/150\n",
      "150/150 [==============================] - 0s 803us/step - loss: 0.0385 - acc: 0.9933 - val_loss: 2.2623 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.68421\n",
      "Epoch 127/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 2.3078 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.68421\n",
      "Epoch 128/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 2.2156 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.68421\n",
      "Epoch 129/150\n",
      "150/150 [==============================] - 0s 883us/step - loss: 0.0355 - acc: 0.9867 - val_loss: 2.3968 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.68421\n",
      "Epoch 130/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0135 - acc: 0.9933 - val_loss: 2.3458 - val_acc: 0.5789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00130: val_acc did not improve from 0.68421\n",
      "Epoch 131/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 2.3084 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.68421\n",
      "Epoch 132/150\n",
      "150/150 [==============================] - 0s 849us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 2.2229 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.68421\n",
      "Epoch 133/150\n",
      "150/150 [==============================] - 0s 871us/step - loss: 0.0085 - acc: 1.0000 - val_loss: 2.1883 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.68421\n",
      "Epoch 134/150\n",
      "150/150 [==============================] - 0s 862us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 2.1812 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.68421\n",
      "Epoch 135/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.1983 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.68421\n",
      "Epoch 136/150\n",
      "150/150 [==============================] - 0s 974us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 2.2200 - val_acc: 0.5263\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.68421\n",
      "Epoch 137/150\n",
      "150/150 [==============================] - 0s 947us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.2313 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.68421\n",
      "Epoch 138/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 2.2416 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.68421\n",
      "Epoch 139/150\n",
      "150/150 [==============================] - 0s 959us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 2.2351 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.68421\n",
      "Epoch 140/150\n",
      "150/150 [==============================] - 0s 976us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 2.2085 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.68421\n",
      "Epoch 141/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 2.2138 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.68421\n",
      "Epoch 142/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 2.2672 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.68421\n",
      "Epoch 143/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 2.3089 - val_acc: 0.5263\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.68421\n",
      "Epoch 144/150\n",
      "150/150 [==============================] - 0s 958us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 2.2893 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.68421\n",
      "Epoch 145/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 2.2810 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.68421\n",
      "Epoch 146/150\n",
      "150/150 [==============================] - 0s 980us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 2.2699 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.68421\n",
      "Epoch 147/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 2.2611 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.68421\n",
      "Epoch 148/150\n",
      "150/150 [==============================] - 0s 905us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 2.2437 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.68421\n",
      "Epoch 149/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 2.2426 - val_acc: 0.6053\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.68421\n",
      "Epoch 150/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 2.2499 - val_acc: 0.6316\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.68421\n"
     ]
    }
   ],
   "source": [
    "checkpoint=ModelCheckpoint(\"best_modelf4.h5\",monitor='val_acc',verbose=True,save_best_only=True)\n",
    "hist=model.fit(embedding_train_matrix,Y_train1,epochs=150,batch_size=64,shuffle=True,validation_split=0.2,callbacks=[checkpoint])\n",
    "#hist=model.fit(embedding_train_matrix,Y_train1,epochs=150,batch_size=64,shuffle=True,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('best_modelf4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_dictionary = {\"1\": \"https://www.youtube.com/embed/bnqLzCsffwY,https://www.youtube.com/embed/iii1NM-Zv1g,https://www.youtube.com/embed/puKD3nkB1h4,https://www.youtube.com/embed/Ax0G_P2dSBw,https://www.youtube.com/embed/Ttxs0PYR6Co\",    \n",
    "                    \"0\": \"https://www.youtube.com/embed/3kxerdAFlv0,https://www.youtube.com/embed/qFkNATtc3mc,https://www.youtube.com/embed/iLf_yqF9VjA,https://www.youtube.com/embed/nJZcbidTutE\",\n",
    "                    \"2\": \"https://www.youtube.com/embed/sDne5fEsxec,https://www.youtube.com/embed/o1RducJbUdc,https://www.youtube.com/embed/asYxxtiWUyw,https://www.youtube.com/embed/hRkc-OPHApY,https://www.youtube.com/embed/GR7ey3EJTRc\",\n",
    "                    \"3\": \"https://www.youtube.com/embed/x6kkDnL8-qw,https://www.youtube.com/embed/gy5_T2ACerk,https://www.youtube.com/embed/JFfEIbGIImk,https://www.youtube.com/embed/UBBHpoW3AKA,https://www.youtube.com/embed/abiL84EAWSY\",\n",
    "                    \"4\": \"https://www.youtube.com/embed/ti2Pxrl2Nho\",\n",
    "                    \"5\":\"https://www.youtube.com/embed/NujNxgy4CpA\",\n",
    "                    \"6\":\"https://www.youtube.com/embed/lkOuyF3Oo9A\",\n",
    "                    \"7\":\"https://www.youtube.com/embed/QpKQjISfB4s\",\n",
    "                    \"8\":\"https://www.youtube.com/embed/GKrpi9NX6LY\",\n",
    "                    \"9\":\"https://www.youtube.com/embed/kd5KqlmcHNo\",\n",
    "                    \"10\":\"https://www.youtube.com/embed/Gl5wBrNuxx4\",\n",
    "                    \"11\":\"https://www.youtube.com/embed/arQWMa8dDrw\"\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TYPE EXIT TO QUIT THE PREDCITON\n",
      "that girl hates me\n",
      "😓 😓\n",
      "THE SONGS YOU CAN LISTEN IS\n",
      "https://www.youtube.com/embed/arQWMa8dDrw\n",
      "TYPE EXIT TO QUIT THE PREDCITON\n",
      "that girl troubles me\n",
      "😓 😓\n",
      "THE SONGS YOU CAN LISTEN IS\n",
      "https://www.youtube.com/embed/Gl5wBrNuxx4\n",
      "TYPE EXIT TO QUIT THE PREDCITON\n",
      "she loves me\n",
      "❤️ ❤️\n",
      "THE SONGS YOU CAN LISTEN IS\n",
      "https://www.youtube.com/embed/nJZcbidTutE\n",
      "TYPE EXIT TO QUIT THE PREDCITON\n",
      "i love her\n",
      "❤️ ❤️\n",
      "THE SONGS YOU CAN LISTEN IS\n",
      "https://www.youtube.com/embed/qFkNATtc3mc\n",
      "TYPE EXIT TO QUIT THE PREDCITON\n",
      "goodbye\n",
      "😁 😁\n",
      "THE SONGS YOU CAN LISTEN IS\n",
      "https://www.youtube.com/embed/hRkc-OPHApY\n",
      "TYPE EXIT TO QUIT THE PREDCITON\n",
      "breakup\n",
      "😓 😓\n",
      "THE SONGS YOU CAN LISTEN IS\n",
      "https://www.youtube.com/embed/kd5KqlmcHNo\n",
      "TYPE EXIT TO QUIT THE PREDCITON\n",
      "exit\n",
      "THANK YOU\n"
     ]
    }
   ],
   "source": [
    "lis=set(string.punctuation)\n",
    "listt=[]\n",
    "while True:\n",
    "    print('TYPE EXIT TO QUIT THE PREDCITON')\n",
    "    words=[str(x.lower()) for x in input().strip().split()]\n",
    "    if 'exit' in words:\n",
    "        print('THANK YOU')\n",
    "        break\n",
    "    strr=[str(x) for x in words if x not in lis]\n",
    "    strr=' '.join(strr)\n",
    "    listt.append(strr)\n",
    "    a=np.array(listt)\n",
    "    listt.pop()\n",
    "    powertext=embedding(a)\n",
    "    powerpred=model.predict_classes(powertext)\n",
    "    #print(strr)\n",
    "    print(emoji.emojize(emoji_dictionary[str(powerpred[0])]),emoji.emojize(emoji_dictionary[str(powerpred[0])]))\n",
    "    number=str(powerpred[0])\n",
    "    print(\"THE SONGS YOU CAN LISTEN IS\")\n",
    "    if 'mom' in words or 'mother' in words or 'mummy' in words or 'mum' in words:\n",
    "        print(music_dictionary['5'])\n",
    "        continue\n",
    "    if 'papa' in words or 'father' in words or 'daddy' in words or 'dad' in words:\n",
    "        print(music_dictionary['6'])\n",
    "        continue\n",
    "    if ('friends' in words or 'friend' in words) and 'love' in words:\n",
    "        print(music_dictionary['7'])\n",
    "        continue\n",
    "    if ('family' in words) and 'love' in words:\n",
    "        print(music_dictionary['8'])\n",
    "        continue\n",
    "    if 'breakup' in words:\n",
    "        print(music_dictionary['9'])\n",
    "        continue\n",
    "    if ('girl' in words and 'troubles' in words):\n",
    "        print(music_dictionary['10'])\n",
    "        continue\n",
    "    if ('girl' in words and 'hates' in words):\n",
    "        print(music_dictionary['11'])\n",
    "        continue\n",
    "    ans=music_dictionary[number]\n",
    "    lines=ans.split(',')\n",
    "    print(np.random.choice(lines))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
